	\documentclass[a4paper,12pt]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{eurosym}
\usepackage{vmargin}
\usepackage{amsmath}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{enumerate}
\usepackage{fancyhdr}

\setcounter{MaxMatrixCols}{10}
%TCIDATA{OutputFilter=LATEX.DLL}
%TCIDATA{Version=5.00.0.2570}
%TCIDATA{<META NAME="SaveForMode"CONTENT="1">}
%TCIDATA{LastRevised=Wednesday, February 23, 201113:24:34}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{Language=American English}

\pagestyle{fancy}
\setmarginsrb{20mm}{0mm}{20mm}{25mm}{12mm}{11mm}{0mm}{11mm}
\lhead{Apache Spark} \rhead{Kevin O'Brien} \chead{The Spark Ecosystem} %\input{tcilatex}

\begin{document}

\section*{MLlib}
%=================================%

\begin{itemize}
\item  MLlib is a machine learning library that provides various algorithms designed to scale out on a cluster for classification, regression, clustering, collaborative filtering, and so on. 
\item Some of these algorithms also work with streaming data, such as linear regression using ordinary least squares or k-means clustering (and more on the way). 
\item Apache Mahout (a machine learning library for Hadoop) has already turned away from MapReduce and joined forces on Spark MLlib.
\end{itemize}
\newpage

The advantages of MLlibâ€™s design include:
\begin{description}
\item[Simplicity:] Simple APIs familiar to data scientists coming from tools like R and Python. Novices are able to run 
algorithms out of the box while experts can easily tune the system by adjusting important knobs and switches (parameters).

\item[Scalability:] Ability to run the same ML code on your laptop and on a big cluster seamlessly without breaking down. 
This lets businesses use the same workflows as their user base and data sets grow.
Streamlined end-to-end: Developing machine learning models is a multistep journey from data ingest through trial 
and error to production. Building MLlib on top of Spark makes it possible to tackle these distinct needs with a 
single tool instead of many disjointed ones. The advantages are lower learning curves, less complex development 
and production environments, and ultimately shorter times to deliver high-performing models.

\item[Compatibility:] Data scientists often have workflows built up in common data science tools, such as R, Python pandas, and 
scikit-learn. Spark DataFrames and MLlib provide tooling that makes it easier to integrate these existing workflows with 
Spark. For example, SparkR allows users to call MLlib algorithms using familiar R syntax, and Databricks is writing 
Spark packages in Python to allow users to distribute parts of scikit-learn workflows.
At the same time, Spark allows data scientists to solve multiple data problems in addition to their machine learning problems. 
\end{description}
The Spark ecosystem can also solve graph computations (via GraphX), streaming (real-time calculations), and real-time 
interactive query processing with Spark SQL and DataFrames. The ability to employ the same framework to solve many 
different problems and use cases allows data professionals to focus on solving their data problems instead of 
learning and maintaining a different 
tool for each scenario.
\end{document}
